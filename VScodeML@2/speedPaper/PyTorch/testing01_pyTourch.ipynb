{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model iTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from layers.Transformer_EncDec import Encoder, EncoderLayer\n",
    "# from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "# from layers.Embed import DataEmbedding_inverted\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class DataEmbedding_inverted(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_inverted, self).__init__()\n",
    "        self.value_embedding = nn.Linear(c_in, d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x: [Batch Variate Time]\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x)\n",
    "        else:\n",
    "            # the potential to take covariates (e.g. timestamps) as tokens\n",
    "            x = self.value_embedding(\n",
    "                torch.cat([x, x_mark.permute(0, 2, 1)], 1))\n",
    "        # x: [Batch Variate d_model]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "\n",
    "\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(\n",
    "                mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / math.sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model,\n",
    "                               out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(\n",
    "            conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(\n",
    "                    x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(\n",
    "                    x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        self.use_norm = configs.use_norm\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding_inverted(configs.seq_len, configs.d_model, configs.embed, configs.freq,\n",
    "                                                    configs.dropout)\n",
    "        self.class_strategy = configs.class_strategy\n",
    "        # Encoder-only architecture\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        self.projector = nn.Linear(\n",
    "            configs.d_model, configs.pred_len, bias=True)\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n",
    "        if self.use_norm:\n",
    "            # Normalization from Non-stationary Transformer\n",
    "            means = x_enc.mean(1, keepdim=True).detach()\n",
    "            x_enc = x_enc - means\n",
    "            stdev = torch.sqrt(\n",
    "                torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "            x_enc /= stdev\n",
    "\n",
    "        _, _, N = x_enc.shape  # B L N\n",
    "        # B: batch_size;    E: d_model;\n",
    "        # L: seq_len;       S: pred_len;\n",
    "        # N: number of variate (tokens), can also includes covariates\n",
    "\n",
    "        # Embedding\n",
    "        # B L N -> B N E                (B L N -> B L E in the vanilla Transformer)\n",
    "        # covariates (e.g timestamp) can be also embedded as tokens\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "\n",
    "        # B N E -> B N E                (B L E -> B L E in the vanilla Transformer)\n",
    "        # the dimensions of embedded time series has been inverted, and then processed by native attn, layernorm and ffn modules\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "\n",
    "        # B N E -> B N S -> B S N\n",
    "        dec_out = self.projector(enc_out).permute(\n",
    "            0, 2, 1)[:, :, :N]  # filter the covariates\n",
    "\n",
    "        if self.use_norm:\n",
    "            # De-Normalization from Non-stationary Transformer\n",
    "            dec_out = dec_out * \\\n",
    "                (stdev[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))\n",
    "            dec_out = dec_out + \\\n",
    "                (means[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))\n",
    "\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "        return dec_out[:, -self.pred_len:, :]  # [B, L, D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.frequencies import to_offset\n",
    "from pandas.tseries import offsets\n",
    "from typing import List\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "ticker = '^GSPC'\n",
    "# ticker = '^NDX'\n",
    "dataset_input = yf.download(ticker, start='1990-01-01',\n",
    "                            end=datetime.now().strftime('%Y-%m-%d'), interval='1d')\n",
    "\n",
    "combined_data = pd.DataFrame({\n",
    "    'Date': dataset_input.index.tolist() * 2,\n",
    "    'Price Type': ['Open'] * len(dataset_input['Open']) + ['Close'] * len(dataset_input['Close']),\n",
    "    'Price': pd.concat([dataset_input['Open'], dataset_input['Close']], ignore_index=True)\n",
    "})\n",
    "\n",
    "# Sort the combined data by Date and Price Type\n",
    "combined_data_sorted = combined_data.sort_values(\n",
    "    by=['Date', 'Price Type']).reset_index(drop=True)\n",
    "price_series = pd.to_numeric(combined_data_sorted['Price'], errors='coerce')\n",
    "price_series = price_series.dropna()\n",
    "\n",
    "data_dict = {\n",
    "    'ETTh1': price_series\n",
    "}\n",
    "\n",
    "# From: gluonts/src/gluonts/time_feature/_base.py\n",
    "# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "# You may not use this file except in compliance with the License.\n",
    "# A copy of the License is located at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is distributed\n",
    "# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "# express or implied. See the License for the specific language governing\n",
    "# permissions and limitations under the License.\n",
    "\n",
    "\n",
    "class TimeFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "class SecondOfMinute(TimeFeature):\n",
    "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "class MinuteOfHour(TimeFeature):\n",
    "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "class HourOfDay(TimeFeature):\n",
    "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfWeek(TimeFeature):\n",
    "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfMonth(TimeFeature):\n",
    "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfYear(TimeFeature):\n",
    "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "class MonthOfYear(TimeFeature):\n",
    "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "class WeekOfYear(TimeFeature):\n",
    "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "\n",
    "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "\n",
    "\n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])\n",
    "\n",
    "\n",
    "def data_provider(args, flag):\n",
    "    Data = data_dict[args.data]\n",
    "    timeenc = 0 if args.embed != 'timeF' else 1\n",
    "\n",
    "    if flag == 'test':\n",
    "        shuffle_flag = False\n",
    "        drop_last = True\n",
    "        batch_size = 1  # bsz=1 for evaluation\n",
    "        freq = args.freq\n",
    "    elif flag == 'pred':\n",
    "        shuffle_flag = False\n",
    "        drop_last = False\n",
    "        batch_size = 1\n",
    "        freq = args.freq\n",
    "        Data = Dataset_Pred\n",
    "    else:\n",
    "        shuffle_flag = True\n",
    "        drop_last = True\n",
    "        batch_size = args.batch_size  # bsz for train and valid\n",
    "        freq = args.freq\n",
    "\n",
    "    data_set = Data(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        flag=flag,\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        features=args.features,\n",
    "        target=args.target,\n",
    "        timeenc=timeenc,\n",
    "        freq=freq,\n",
    "    )\n",
    "    print(flag, len(data_set))\n",
    "    data_loader = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_flag,\n",
    "        num_workers=args.num_workers,\n",
    "        drop_last=drop_last)\n",
    "    return data_set, data_loader\n",
    "\n",
    "\n",
    "class Dataset_Pred(Dataset):\n",
    "    def __init__(self, root_path, flag='pred', size=None,\n",
    "                 features='S', data_path='ETTh1.csv',\n",
    "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        if size == None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['pred']\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.inverse = inverse\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.cols = cols\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
    "                                          self.data_path))\n",
    "        '''\n",
    "        df_raw.columns: ['date', ...(other features), target feature]\n",
    "        '''\n",
    "        if self.cols:\n",
    "            cols = self.cols.copy()\n",
    "            cols.remove(self.target)\n",
    "        else:\n",
    "            cols = list(df_raw.columns)\n",
    "            cols.remove(self.target)\n",
    "            cols.remove('date')\n",
    "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
    "        border1 = len(df_raw) - self.seq_len\n",
    "        border2 = len(df_raw)\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            self.scaler.fit(df_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "\n",
    "        tmp_stamp = df_raw[['date']][border1:border2]\n",
    "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "        pred_dates = pd.date_range(\n",
    "            tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
    "\n",
    "        df_stamp = pd.DataFrame(columns=['date'])\n",
    "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "            df_stamp['weekday'] = df_stamp.date.apply(\n",
    "                lambda row: row.weekday(), 1)\n",
    "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
    "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
    "            data_stamp = df_stamp.drop(['date'], 1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(\n",
    "                df_stamp['date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        if self.inverse:\n",
    "            self.data_y = df_data.values[border1:border2]\n",
    "        else:\n",
    "            self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        if self.inverse:\n",
    "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
    "        else:\n",
    "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exp long term forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from model import Transformer, Informer, Reformer, Flowformer, Flashformer, \\\n",
    "#     iTransformer, iInformer, iReformer, iFlowformer, iFlashformer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from experiments.exp_basic import Exp_Basic\n",
    "# from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "# from utils.metrics import metric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
    "    if args.lradj == 'type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
    "    elif args.lradj == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {\n",
    "                  self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({\n",
    "                  self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "class StandardScaler():\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def transform(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return (data * self.std) + self.mean\n",
    "\n",
    "\n",
    "def visual(true, preds=None, name='./pic/test.pdf'):\n",
    "    \"\"\"\n",
    "    Results visualization\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.plot(true, label='GroundTruth', linewidth=2)\n",
    "    if preds is not None:\n",
    "        plt.plot(preds, label='Prediction', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.savefig(name, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def adjustment(gt, pred):\n",
    "    anomaly_state = False\n",
    "    for i in range(len(gt)):\n",
    "        if gt[i] == 1 and pred[i] == 1 and not anomaly_state:\n",
    "            anomaly_state = True\n",
    "            for j in range(i, 0, -1):\n",
    "                if gt[j] == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    if pred[j] == 0:\n",
    "                        pred[j] = 1\n",
    "            for j in range(i, len(gt)):\n",
    "                if gt[j] == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    if pred[j] == 0:\n",
    "                        pred[j] = 1\n",
    "        elif gt[i] == 0:\n",
    "            anomaly_state = False\n",
    "        if anomaly_state:\n",
    "            pred[i] = 1\n",
    "    return gt, pred\n",
    "\n",
    "\n",
    "def cal_accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "\n",
    "def RSE(pred, true):\n",
    "    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\n",
    "\n",
    "\n",
    "def CORR(pred, true):\n",
    "    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n",
    "    d = np.sqrt(((true - true.mean(0)) ** 2 *\n",
    "                (pred - pred.mean(0)) ** 2).sum(0))\n",
    "    return (u / d).mean(-1)\n",
    "\n",
    "\n",
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "\n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred - true) ** 2)\n",
    "\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))\n",
    "\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "def MSPE(pred, true):\n",
    "    return np.mean(np.square((pred - true) / true))\n",
    "\n",
    "\n",
    "def metric(pred, true):\n",
    "    mae = MAE(pred, true)\n",
    "    mse = MSE(pred, true)\n",
    "    rmse = RMSE(pred, true)\n",
    "    mape = MAPE(pred, true)\n",
    "    mspe = MSPE(pred, true)\n",
    "\n",
    "    return mae, mse, rmse, mape, mspe\n",
    "\n",
    "\n",
    "class Exp_Basic(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.model_dict = {\n",
    "            'iTransformer': iTransformer\n",
    "        }\n",
    "        self.device = self._acquire_device()\n",
    "        self.model = self._build_model().to(self.device)\n",
    "\n",
    "    def _build_model(self):\n",
    "        raise NotImplementedError\n",
    "        return None\n",
    "\n",
    "    def _acquire_device(self):\n",
    "        if self.args.use_gpu:\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
    "                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n",
    "            device = torch.device('cuda:{}'.format(self.args.gpu))\n",
    "            print('Use GPU: cuda:{}'.format(self.args.gpu))\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print('Use CPU')\n",
    "        return device\n",
    "\n",
    "    def _get_data(self):\n",
    "        pass\n",
    "\n",
    "    def vali(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Exp_Long_Term_Forecast(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Long_Term_Forecast, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = self.model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(\n",
    "            self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "                    batch_x_mark = None\n",
    "                    batch_y_mark = None\n",
    "                else:\n",
    "                    batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                    batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                  f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "                    batch_x_mark = None\n",
    "                    batch_y_mark = None\n",
    "                else:\n",
    "                    batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                    batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                        batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                          f_dim:].to(self.device)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                      f_dim:].to(self.device)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(\n",
    "                        i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * \\\n",
    "                        ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print(\n",
    "                        '\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(\n",
    "                epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "\n",
    "            # get_cka(self.args, setting, self.model, train_loader, self.device, epoch)\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def test(self, setting, test=0):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join(\n",
    "                './checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "                    batch_x_mark = None\n",
    "                    batch_y_mark = None\n",
    "                else:\n",
    "                    batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                    batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                  f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "                if test_data.scale and self.args.inverse:\n",
    "                    shape = outputs.shape\n",
    "                    outputs = test_data.inverse_transform(\n",
    "                        outputs.squeeze(0)).reshape(shape)\n",
    "                    batch_y = test_data.inverse_transform(\n",
    "                        batch_y.squeeze(0)).reshape(shape)\n",
    "\n",
    "                pred = outputs\n",
    "                true = batch_y\n",
    "\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                if i % 20 == 0:\n",
    "                    input = batch_x.detach().cpu().numpy()\n",
    "                    if test_data.scale and self.args.inverse:\n",
    "                        shape = input.shape\n",
    "                        input = test_data.inverse_transform(\n",
    "                            input.squeeze(0)).reshape(shape)\n",
    "                    gt = np.concatenate(\n",
    "                        (input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                    pd = np.concatenate(\n",
    "                        (input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "        print('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f = open(\"result_long_term_forecast.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        np.save(folder_path + 'metrics.npy',\n",
    "                np.array([mae, mse, rmse, mape, mspe]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        np.save(folder_path + 'true.npy', trues)\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "\n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path + '/' + 'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                if pred_data.scale and self.args.inverse:\n",
    "                    shape = outputs.shape\n",
    "                    outputs = pred_data.inverse_transform(\n",
    "                        outputs.squeeze(0)).reshape(shape)\n",
    "                preds.append(outputs)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        np.save(folder_path + 'real_prediction.npy', preds)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exp_Long_Term_Forecast_Partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pdb\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# train on partial variate data and test on the full variates, used for two types of experiments:\n",
    "# (1) Generalize on unseen variate (Figure 5 of our paper)\n",
    "# (2) Efficient training strategy  (Figure 8 of our paper)\n",
    "class Exp_Long_Term_Forecast_Partial(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Long_Term_Forecast_Partial, self).__init__(args)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = self.model_dict[self.args.model].Model(self.args).float()\n",
    "\n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(\n",
    "            self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion, partial_train=False):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "\n",
    "                if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "                    batch_x_mark = None\n",
    "                    batch_y_mark = None\n",
    "                else:\n",
    "                    batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                    batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                if partial_train:  # we train models with only partial variates from the dataset\n",
    "                    partial_start = self.args.partial_start_index\n",
    "                    partial_end = min(self.args.enc_in +\n",
    "                                      partial_start, batch_x.shape[-1])\n",
    "                    batch_x = batch_x[:, :, partial_start:partial_end]\n",
    "                    batch_y = batch_y[:, :, partial_start:partial_end]\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    elif self.args.channel_independence:\n",
    "                        B, Tx, N = batch_x.shape\n",
    "                        _, Ty, _ = dec_inp.shape\n",
    "                        if batch_x_mark == None:\n",
    "                            outputs = self.model(batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1), batch_x_mark,\n",
    "                                                 dec_inp.permute(0, 2, 1).reshape(B * N, Ty, 1), batch_y_mark).reshape(\n",
    "                                B, N, -1).permute(0, 2, 1)\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1),\n",
    "                                                 batch_x_mark.repeat(N, 1, 1),\n",
    "                                                 dec_inp.permute(0, 2, 1).reshape(\n",
    "                                                     B * N, Ty, 1),\n",
    "                                                 batch_y_mark.repeat(N, 1, 1)) \\\n",
    "                                .reshape(B, N, -1).permute(0, 2, 1)\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                  f_dim:].to(self.device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=self.args.patience, verbose=True)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "                    batch_x_mark = None\n",
    "                    batch_y_mark = None\n",
    "                else:\n",
    "                    batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                    batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # Variate Generalization training:\n",
    "                # We train with partial variates (args.enc_in < number of dataset variates)\n",
    "                # and test the obtained model directly on all variates.\n",
    "                partial_start = self.args.partial_start_index\n",
    "                partial_end = min(self.args.enc_in +\n",
    "                                  partial_start, batch_x.shape[-1])\n",
    "                batch_x = batch_x[:, :, partial_start:partial_end]\n",
    "                batch_y = batch_y[:, :, partial_start:partial_end]\n",
    "                # Efficient training strategy: randomly choose part of the variates\n",
    "                # and only train the model with selected variates in each batch\n",
    "                if self.args.efficient_training:\n",
    "                    _, _, N = batch_x.shape\n",
    "                    index = np.stack(random.sample(\n",
    "                        range(N), N))[-self.args.enc_in:]\n",
    "                    batch_x = batch_x[:, :, index]\n",
    "                    batch_y = batch_y[:, :, index]\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                        batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                          f_dim:].to(self.device)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    elif self.args.channel_independence:\n",
    "                        B, Tx, N = batch_x.shape\n",
    "                        _, Ty, _ = dec_inp.shape\n",
    "                        if batch_x_mark == None:\n",
    "                            outputs = self.model(batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1), batch_x_mark,\n",
    "                                                 dec_inp.permute(0, 2, 1).reshape(B * N, Ty, 1), batch_y_mark).reshape(\n",
    "                                B, N, -1).permute(0, 2, 1)\n",
    "                        else:\n",
    "                            a = batch_x.permute(0, 2, 1)\n",
    "                            b = batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1)\n",
    "                            outputs = self.model(batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1),\n",
    "                                                 batch_x_mark.repeat(N, 1, 1),\n",
    "                                                 dec_inp.permute(0, 2, 1).reshape(\n",
    "                                                     B * N, Ty, 1),\n",
    "                                                 batch_y_mark.repeat(N, 1, 1)) \\\n",
    "                                .reshape(B, N, -1).permute(0, 2, 1)\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                    batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                      f_dim:].to(self.device)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(\n",
    "                        i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * \\\n",
    "                        ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print(\n",
    "                        '\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(\n",
    "                epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader,\n",
    "                                  criterion, partial_train=True)\n",
    "            test_loss = self.vali(test_data, test_loader,\n",
    "                                  criterion, partial_train=False)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "\n",
    "        best_model_path = path + '/' + 'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def test(self, setting, test=0):\n",
    "\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(os.path.join(\n",
    "                './checkpoints/' + setting, 'checkpoint.pth')))\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                # During model inference, test the obtained model directly on all variates.\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "                    batch_x_mark = None\n",
    "                    batch_y_mark = None\n",
    "                else:\n",
    "                    batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                    batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    elif self.args.channel_independence:  # compare the result with channel_independence\n",
    "                        B, Tx, N = batch_x.shape\n",
    "                        _, Ty, _ = dec_inp.shape\n",
    "                        if batch_x_mark == None:\n",
    "                            outputs = self.model(batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1), batch_x_mark,\n",
    "                                                 dec_inp.permute(0, 2, 1).reshape(B * N, Ty, 1), batch_y_mark).reshape(\n",
    "                                B, N, -1).permute(0, 2, 1)\n",
    "                        else:\n",
    "                            outputs = self.model(batch_x.permute(0, 2, 1).reshape(B * N, Tx, 1),\n",
    "                                                 batch_x_mark.repeat(N, 1, 1),\n",
    "                                                 dec_inp.permute(0, 2, 1).reshape(\n",
    "                                                     B * N, Ty, 1),\n",
    "                                                 batch_y_mark.repeat(N, 1, 1)) \\\n",
    "                                .reshape(B, N, -1).permute(0, 2, 1)\n",
    "                    else:\n",
    "                        # directly test the trained model on all variates without fine-tuning.\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "                f_dim = -1 if self.args.features == 'MS' else 0\n",
    "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -self.args.pred_len:,\n",
    "                                  f_dim:].to(self.device)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                batch_y = batch_y.detach().cpu().numpy()\n",
    "                if test_data.scale and self.args.inverse:\n",
    "                    shape = outputs.shape\n",
    "                    outputs = test_data.inverse_transform(\n",
    "                        outputs.squeeze(0)).reshape(shape)\n",
    "                    batch_y = test_data.inverse_transform(\n",
    "                        batch_y.squeeze(0)).reshape(shape)\n",
    "\n",
    "                pred = outputs\n",
    "                true = batch_y\n",
    "\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                if i % 20 == 0:\n",
    "                    input = batch_x.detach().cpu().numpy()\n",
    "                    if test_data.scale and self.args.inverse:\n",
    "                        shape = input.shape\n",
    "                        input = test_data.inverse_transform(\n",
    "                            input.squeeze(0)).reshape(shape)\n",
    "                    gt = np.concatenate(\n",
    "                        (input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                    pd = np.concatenate(\n",
    "                        (input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "        print('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f = open(\"result_long_term_forecast.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        np.save(folder_path + 'metrics.npy',\n",
    "                np.array([mae, mse, rmse, mape, mspe]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        np.save(folder_path + 'true.npy', trues)\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "\n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path + '/' + 'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        preds = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
    "                batch_x = batch_x.float().to(self.device)\n",
    "                batch_y = batch_y.float().to(self.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "                # decoder input\n",
    "                dec_inp = torch.zeros_like(\n",
    "                    batch_y[:, -self.args.pred_len:, :]).float()\n",
    "                dec_inp = torch.cat(\n",
    "                    [batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "                # encoder - decoder\n",
    "                if self.args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        if self.args.output_attention:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                        else:\n",
    "                            outputs = self.model(\n",
    "                                batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                else:\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                if pred_data.scale and self.args.inverse:\n",
    "                    shape = outputs.shape\n",
    "                    outputs = pred_data.inverse_transform(\n",
    "                        outputs.squeeze(0)).reshape(shape)\n",
    "                preds.append(outputs)\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        np.save(folder_path + 'real_prediction.npy', preds)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --is_training IS_TRAINING --model_id\n",
      "                             MODEL_ID --model MODEL --data DATA\n",
      "                             [--root_path ROOT_PATH] [--data_path DATA_PATH]\n",
      "                             [--features FEATURES] [--target TARGET]\n",
      "                             [--freq FREQ] [--checkpoints CHECKPOINTS]\n",
      "                             [--seq_len SEQ_LEN] [--label_len LABEL_LEN]\n",
      "                             [--pred_len PRED_LEN] [--enc_in ENC_IN]\n",
      "                             [--dec_in DEC_IN] [--c_out C_OUT]\n",
      "                             [--d_model D_MODEL] [--n_heads N_HEADS]\n",
      "                             [--e_layers E_LAYERS] [--d_layers D_LAYERS]\n",
      "                             [--d_ff D_FF] [--moving_avg MOVING_AVG]\n",
      "                             [--factor FACTOR] [--distil] [--dropout DROPOUT]\n",
      "                             [--embed EMBED] [--activation ACTIVATION]\n",
      "                             [--output_attention] [--do_predict]\n",
      "                             [--num_workers NUM_WORKERS] [--itr ITR]\n",
      "                             [--train_epochs TRAIN_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE] [--patience PATIENCE]\n",
      "                             [--learning_rate LEARNING_RATE] [--des DES]\n",
      "                             [--loss LOSS] [--lradj LRADJ] [--use_amp]\n",
      "                             [--exp_name EXP_NAME]\n",
      "                             [--channel_independence CHANNEL_INDEPENDENCE]\n",
      "                             [--inverse] [--class_strategy CLASS_STRATEGY]\n",
      "                             [--target_root_path TARGET_ROOT_PATH]\n",
      "                             [--target_data_path TARGET_DATA_PATH]\n",
      "                             [--efficient_training EFFICIENT_TRAINING]\n",
      "                             [--use_norm USE_NORM]\n",
      "                             [--partial_start_index PARTIAL_START_INDEX]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/Users/porchportal2/Library/Jupyter/runtime/kernel-v3cf9e9bcc005de9de666f6ff65d9c819a9d1101c3.json could match --features, --freq, --factor\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "# from experiments.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "# from experiments.exp_long_term_forecasting_partial import Exp_Long_Term_Forecast_Partial\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fix_seed = 2023\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='iTransformer')\n",
    "\n",
    "    # basic config\n",
    "    parser.add_argument('--is_training', type=int,\n",
    "                        required=True, default=1, help='status')\n",
    "    parser.add_argument('--model_id', type=str, required=True,\n",
    "                        default='test', help='model id')\n",
    "    parser.add_argument('--model', type=str, required=True, default='iTransformer',\n",
    "                        help='model name, options: [iTransformer, iInformer, iReformer, iFlowformer, iFlashformer]')\n",
    "\n",
    "    # data loader\n",
    "    parser.add_argument('--data', type=str, required=True,\n",
    "                        default='custom', help='dataset type')\n",
    "    parser.add_argument('--root_path', type=str,\n",
    "                        default='./data/electricity/', help='root path of the data file')\n",
    "    parser.add_argument('--data_path', type=str,\n",
    "                        default='electricity.csv', help='data csv file')\n",
    "    parser.add_argument('--features', type=str, default='M',\n",
    "                        help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "    parser.add_argument('--target', type=str, default='OT',\n",
    "                        help='target feature in S or MS task')\n",
    "    parser.add_argument('--freq', type=str, default='h',\n",
    "                        help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "    parser.add_argument('--checkpoints', type=str,\n",
    "                        default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "    # forecasting task\n",
    "    parser.add_argument('--seq_len', type=int, default=96,\n",
    "                        help='input sequence length')\n",
    "    # no longer needed in inverted Transformers\n",
    "    parser.add_argument('--label_len', type=int,\n",
    "                        default=48, help='start token length')\n",
    "    parser.add_argument('--pred_len', type=int, default=96,\n",
    "                        help='prediction sequence length')\n",
    "\n",
    "    # model define\n",
    "    parser.add_argument('--enc_in', type=int, default=7,\n",
    "                        help='encoder input size')\n",
    "    parser.add_argument('--dec_in', type=int, default=7,\n",
    "                        help='decoder input size')\n",
    "    # applicable on arbitrary number of variates in inverted Transformers\n",
    "    parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "    parser.add_argument('--d_model', type=int, default=512,\n",
    "                        help='dimension of model')\n",
    "    parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "    parser.add_argument('--e_layers', type=int, default=2,\n",
    "                        help='num of encoder layers')\n",
    "    parser.add_argument('--d_layers', type=int, default=1,\n",
    "                        help='num of decoder layers')\n",
    "    parser.add_argument('--d_ff', type=int, default=2048,\n",
    "                        help='dimension of fcn')\n",
    "    parser.add_argument('--moving_avg', type=int, default=25,\n",
    "                        help='window size of moving average')\n",
    "    parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "    parser.add_argument('--distil', action='store_false',\n",
    "                        help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                        default=True)\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "    parser.add_argument('--embed', type=str, default='timeF',\n",
    "                        help='time features encoding, options:[timeF, fixed, learned]')\n",
    "    parser.add_argument('--activation', type=str,\n",
    "                        default='gelu', help='activation')\n",
    "    parser.add_argument('--output_attention', action='store_true',\n",
    "                        help='whether to output attention in ecoder')\n",
    "    parser.add_argument('--do_predict', action='store_true',\n",
    "                        help='whether to predict unseen future data')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--num_workers', type=int,\n",
    "                        default=10, help='data loader num workers')\n",
    "    parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "    parser.add_argument('--train_epochs', type=int,\n",
    "                        default=10, help='train epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='batch size of train input data')\n",
    "    parser.add_argument('--patience', type=int, default=3,\n",
    "                        help='early stopping patience')\n",
    "    parser.add_argument('--learning_rate', type=float,\n",
    "                        default=0.0001, help='optimizer learning rate')\n",
    "    parser.add_argument('--des', type=str, default='test',\n",
    "                        help='exp description')\n",
    "    parser.add_argument('--loss', type=str, default='MSE',\n",
    "                        help='loss function')\n",
    "    parser.add_argument('--lradj', type=str, default='type1',\n",
    "                        help='adjust learning rate')\n",
    "    parser.add_argument('--use_amp', action='store_true',\n",
    "                        help='use automatic mixed precision training', default=False)\n",
    "\n",
    "    # iTransformer\n",
    "    parser.add_argument('--exp_name', type=str, required=False, default='MTSF',\n",
    "                        help='experiemnt name, options:[MTSF, partial_train]')\n",
    "    parser.add_argument('--channel_independence', type=bool, default=False,\n",
    "                        help='whether to use channel_independence mechanism')\n",
    "    parser.add_argument('--inverse', action='store_true',\n",
    "                        help='inverse output data', default=False)\n",
    "    parser.add_argument('--class_strategy', type=str,\n",
    "                        default='projection', help='projection/average/cls_token')\n",
    "    parser.add_argument('--target_root_path', type=str,\n",
    "                        default='./data/electricity/', help='root path of the data file')\n",
    "    parser.add_argument('--target_data_path', type=str,\n",
    "                        default='electricity.csv', help='data file')\n",
    "    parser.add_argument('--efficient_training', type=bool, default=False,\n",
    "                        # See Figure 8 of our paper for the detail\n",
    "                        help='whether to use efficient_training (exp_name should be partial train)')\n",
    "    parser.add_argument('--use_norm', type=int,\n",
    "                        default=True, help='use norm and denorm')\n",
    "    parser.add_argument('--partial_start_index', type=int, default=0, help='the start index of variates for partial training, '\n",
    "                                                                           'you can select [partial_start_index, min(enc_in + partial_start_index, N)]')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "    if args.use_gpu and args.use_multi_gpu:\n",
    "        args.devices = args.devices.replace(' ', '')\n",
    "        device_ids = args.devices.split(',')\n",
    "        args.device_ids = [int(id_) for id_ in device_ids]\n",
    "        args.gpu = args.device_ids[0]\n",
    "\n",
    "    print('Args in experiment:')\n",
    "    print(args)\n",
    "\n",
    "    if args.exp_name == 'partial_train':  # See Figure 8 of our paper, for the detail\n",
    "        Exp = Exp_Long_Term_Forecast_Partial\n",
    "    else:  # MTSF: multivariate time series forecasting\n",
    "        Exp = Exp_Long_Term_Forecast\n",
    "\n",
    "    if args.is_training:\n",
    "        for ii in range(args.itr):\n",
    "            # setting record of experiments\n",
    "            setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "                args.model_id,\n",
    "                args.model,\n",
    "                args.data,\n",
    "                args.features,\n",
    "                args.seq_len,\n",
    "                args.label_len,\n",
    "                args.pred_len,\n",
    "                args.d_model,\n",
    "                args.n_heads,\n",
    "                args.e_layers,\n",
    "                args.d_layers,\n",
    "                args.d_ff,\n",
    "                args.factor,\n",
    "                args.embed,\n",
    "                args.distil,\n",
    "                args.des,\n",
    "                args.class_strategy, ii)\n",
    "\n",
    "            exp = Exp(args)  # set experiments\n",
    "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "            exp.train(setting)\n",
    "\n",
    "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.test(setting)\n",
    "\n",
    "            if args.do_predict:\n",
    "                print(\n",
    "                    '>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "                exp.predict(setting, True)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        ii = 0\n",
    "        setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.features,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            args.d_model,\n",
    "            args.n_heads,\n",
    "            args.e_layers,\n",
    "            args.d_layers,\n",
    "            args.d_ff,\n",
    "            args.factor,\n",
    "            args.embed,\n",
    "            args.distil,\n",
    "            args.des,\n",
    "            args.class_strategy, ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting, test=1)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ETL:\n",
    "    \"\"\"\n",
    "    ticker: str\n",
    "    period: string\n",
    "    test_size: float betwee 0 and 1\n",
    "    n_input: int\n",
    "    timestep: int\n",
    "    Extracts data for stock with ticker `ticker` from yf api,\n",
    "    splits the data into train and test sets by date,\n",
    "    reshapes the data into np.array of shape [#weeks, 5, 1],\n",
    "    converts our problem into supervised learning problem.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, datainput, test_size=0.2, n_input=5, timestep=5, normalize_bool=False, scaler=None, target_col=None) -> None:\n",
    "        self.datainput = datainput\n",
    "        self.test_size = test_size\n",
    "        self.n_input = n_input\n",
    "        self.timestep = timestep\n",
    "        self.normalize_bool = normalize_bool\n",
    "        self.scaler = scaler\n",
    "        self.target_col = target_col\n",
    "        self.df = self.extract_historic_data()\n",
    "        self.train, self.test = self.etl()\n",
    "        self.X_train, self.y_train = self.to_supervised(self.train)\n",
    "        self.X_test, self.y_test = self.to_supervised(self.test)\n",
    "\n",
    "        if self.normalize_bool:\n",
    "            print('normalized', normalize_bool)\n",
    "            self.scaler = scaler\n",
    "        else:\n",
    "            print('not normalized', normalize_bool)\n",
    "            self.scaler = None\n",
    "\n",
    "    def extract_historic_data(self) -> pd.DataFrame:\n",
    "        if self.normalize_bool:\n",
    "            data = self.scaler.fit_transform(self.datainput)\n",
    "            return pd.DataFrame(data, columns=self.datainput.columns)\n",
    "        else:\n",
    "            # return self.datainput]\n",
    "            return pd.DataFrame(self.datainput, columns=self.datainput.columns)\n",
    "\n",
    "    def split_data(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Splits our pd.Series into train and test series with\n",
    "        test series representing test_size * 100 % of data.\n",
    "        \"\"\"\n",
    "        # data = self.extract_historic_data()\n",
    "        data = self.df\n",
    "        if len(data) != 0:\n",
    "            train_idx = round(len(data) * (1 - self.test_size))\n",
    "            train = data.iloc[:train_idx]\n",
    "            test = data.iloc[train_idx:]\n",
    "            return train, test\n",
    "        else:\n",
    "            raise Exception('Data set is empty, cannot split.')\n",
    "\n",
    "    def window_and_reshape(self, data) -> np.array:\n",
    "        \"\"\"\n",
    "        Reformats data into shape our model needs.\n",
    "        \"\"\"\n",
    "        samples = data.shape[0] // self.timestep\n",
    "        if samples <= 0:\n",
    "            raise ValueError(\n",
    "                \"The number of samples is less than or equal to 0. Ensure data length is greater than timestep.\")\n",
    "        result = np.array_split(data[:samples * self.timestep], samples)\n",
    "        return np.array(result)\n",
    "\n",
    "    def transform(self, train, test) -> np.array:\n",
    "        train_remainder = train.shape[0] % self.timestep\n",
    "        test_remainder = test.shape[0] % self.timestep\n",
    "        if train_remainder != 0:\n",
    "            train = train[:-(train_remainder)]\n",
    "        if test_remainder != 0:\n",
    "            test = test[:-(test_remainder)]\n",
    "        # print(\"train:\", train, \"test:\", test)\n",
    "        if len(train) < self.timestep or len(test) < self.timestep:\n",
    "            raise ValueError(\n",
    "                \"Not enough data to form at least one timestep window.\")\n",
    "        train_transformed, test_transformed = self.window_and_reshape(\n",
    "            train), self.window_and_reshape(test)\n",
    "        print(f'train_transformed shape: {train_transformed.shape}')\n",
    "        print(f'test_transformed shape: {test_transformed.shape}')\n",
    "        return train_transformed, test_transformed\n",
    "\n",
    "    def etl(self) -> tuple[np.array, np.array]:\n",
    "        \"\"\"\n",
    "        Runs complete ETL\n",
    "        \"\"\"\n",
    "        train, test = self.split_data()\n",
    "        print(\"train:\", train, \"test:\", test)\n",
    "        return self.transform(train, test)\n",
    "\n",
    "    def to_supervised(self, data, n_out=5) -> tuple:\n",
    "        X, y = [], []\n",
    "        for sample in data:\n",
    "            if len(sample) >= self.n_input + n_out:\n",
    "                for i in range(len(sample) - self.n_input - n_out + 1):\n",
    "                    X.append(sample[i:i + self.n_input])\n",
    "                    y.append(sample[i + self.n_input:i +\n",
    "                             self.n_input + n_out, :])\n",
    "        print(len(sample) - self.n_input - n_out + 1)\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        print(f'X shape: {X.shape}')\n",
    "        print(f'y shape: {y.shape}')\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:              Close\n",
      "0       359.690002\n",
      "1       353.399994\n",
      "2       358.760010\n",
      "3       359.690002\n",
      "4       355.670013\n",
      "...            ...\n",
      "15725  3949.570068\n",
      "15726  3915.459961\n",
      "15727  3953.500000\n",
      "15728  3913.100098\n",
      "15729  3913.139893\n",
      "\n",
      "[15730 rows x 1 columns] test:              Close\n",
      "15730  3940.590088\n",
      "15731  3916.479980\n",
      "15732  3910.520020\n",
      "15733  3937.600098\n",
      "15734  3889.139893\n",
      "...            ...\n",
      "17473  5507.330078\n",
      "17474  5471.049805\n",
      "17475  5442.069824\n",
      "17476  5495.520020\n",
      "17477  5490.509766\n",
      "\n",
      "[1748 rows x 1 columns]\n",
      "train_transformed shape: (1573, 10, 1)\n",
      "test_transformed shape: (174, 10, 1)\n",
      "1\n",
      "X shape: (1573, 5, 1)\n",
      "y shape: (1573, 5, 1)\n",
      "1\n",
      "X shape: (174, 5, 1)\n",
      "y shape: (174, 5, 1)\n",
      "not normalized False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset_input1 = pd.DataFrame({\n",
    "    'Close': price_series,\n",
    "    # 'DEMA': data01,\n",
    "    # 'TEMA': data02,\n",
    "    # 'WMA': dataWMA,\n",
    "    # 'SMA_5': dataSMA_5,\n",
    "    # 'EMA_5': dataEMA_5,\n",
    "    # 'SMA_10': dataSMA_10,\n",
    "    # 'EMA_10': dataEMA_10,\n",
    "    # 'ZLEMA': dataZLEMA,\n",
    "    # # 'FRAMA': dataFRAMA\n",
    "    # 'EMA_20': dataEMA_20\n",
    "})\n",
    "# Example of data input (replace with your actual data)\n",
    "etl = ETL(\n",
    "    datainput=dataset_input1.dropna(),\n",
    "    test_size=0.1,\n",
    "    n_input=5,  # Look-back period\n",
    "    timestep=10,  # Number of past days to use for each prediction\n",
    "    normalize_bool=False,\n",
    "    scaler=MinMaxScaler,\n",
    "    target_col='price'\n",
    ")\n",
    "\n",
    "# The processed data is now available in:\n",
    "X_train, y_train = etl.X_train, etl.y_train\n",
    "X_test, y_test = etl.X_test, etl.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 527.2335\n",
      "Epoch [10/100], Loss: 526.3246\n",
      "Epoch [15/100], Loss: 525.4137\n",
      "Epoch [20/100], Loss: 524.4996\n",
      "Epoch [25/100], Loss: 523.5814\n",
      "Epoch [30/100], Loss: 522.6583\n",
      "Epoch [35/100], Loss: 521.7295\n",
      "Epoch [40/100], Loss: 520.7942\n",
      "Epoch [45/100], Loss: 519.8522\n",
      "Epoch [50/100], Loss: 518.9032\n",
      "Epoch [55/100], Loss: 517.9470\n",
      "Epoch [60/100], Loss: 516.9836\n",
      "Epoch [65/100], Loss: 516.0133\n",
      "Epoch [70/100], Loss: 515.0362\n",
      "Epoch [75/100], Loss: 514.0528\n",
      "Epoch [80/100], Loss: 513.0634\n",
      "Epoch [85/100], Loss: 512.0686\n",
      "Epoch [90/100], Loss: 511.0689\n",
      "Epoch [95/100], Loss: 510.0648\n",
      "Epoch [100/100], Loss: 509.0573\n",
      "Predictions: tensor([[[3922.2166],\n",
      "         [3917.3262],\n",
      "         [3904.6899],\n",
      "         [3934.2488],\n",
      "         [3903.1743]],\n",
      "\n",
      "        [[3967.9802],\n",
      "         [3966.6018],\n",
      "         [3963.0405],\n",
      "         [3971.3713],\n",
      "         [3962.6133]],\n",
      "\n",
      "        [[4081.7385],\n",
      "         [4079.4697],\n",
      "         [4073.6067],\n",
      "         [4087.3213],\n",
      "         [4072.9036]],\n",
      "\n",
      "        [[4144.4761],\n",
      "         [4140.3804],\n",
      "         [4129.7979],\n",
      "         [4154.5527],\n",
      "         [4128.5288]],\n",
      "\n",
      "        [[4149.2397],\n",
      "         [4144.7856],\n",
      "         [4133.2764],\n",
      "         [4160.1987],\n",
      "         [4131.8960]],\n",
      "\n",
      "        [[4192.7974],\n",
      "         [4190.1040],\n",
      "         [4183.1455],\n",
      "         [4199.4233],\n",
      "         [4182.3110]],\n",
      "\n",
      "        [[4180.3032],\n",
      "         [4176.9331],\n",
      "         [4168.2251],\n",
      "         [4188.5947],\n",
      "         [4167.1807]],\n",
      "\n",
      "        [[4127.5107],\n",
      "         [4119.0381],\n",
      "         [4097.1460],\n",
      "         [4148.3564],\n",
      "         [4094.5208]],\n",
      "\n",
      "        [[4137.9541],\n",
      "         [4131.3125],\n",
      "         [4114.1504],\n",
      "         [4154.2959],\n",
      "         [4112.0923]],\n",
      "\n",
      "        [[4197.6357],\n",
      "         [4195.9863],\n",
      "         [4191.7241],\n",
      "         [4201.6943],\n",
      "         [4191.2134]],\n",
      "\n",
      "        [[4208.2822],\n",
      "         [4204.6909],\n",
      "         [4195.4116],\n",
      "         [4217.1182],\n",
      "         [4194.2983]],\n",
      "\n",
      "        [[4235.2197],\n",
      "         [4232.7734],\n",
      "         [4226.4531],\n",
      "         [4241.2388],\n",
      "         [4225.6948]],\n",
      "\n",
      "        [[4221.0439],\n",
      "         [4214.0469],\n",
      "         [4195.9663],\n",
      "         [4238.2603],\n",
      "         [4193.7979]],\n",
      "\n",
      "        [[4261.4619],\n",
      "         [4257.9478],\n",
      "         [4248.8667],\n",
      "         [4270.1089],\n",
      "         [4247.7778]],\n",
      "\n",
      "        [[4316.1870],\n",
      "         [4310.4141],\n",
      "         [4295.4971],\n",
      "         [4330.3911],\n",
      "         [4293.7080]],\n",
      "\n",
      "        [[4349.8354],\n",
      "         [4342.9087],\n",
      "         [4325.0117],\n",
      "         [4366.8770],\n",
      "         [4322.8652]],\n",
      "\n",
      "        [[4343.8462],\n",
      "         [4333.0151],\n",
      "         [4305.0288],\n",
      "         [4370.4951],\n",
      "         [4301.6724]],\n",
      "\n",
      "        [[4393.0972],\n",
      "         [4386.8359],\n",
      "         [4370.6572],\n",
      "         [4408.5024],\n",
      "         [4368.7173]],\n",
      "\n",
      "        [[4401.9854],\n",
      "         [4399.1694],\n",
      "         [4391.8940],\n",
      "         [4408.9131],\n",
      "         [4391.0215]],\n",
      "\n",
      "        [[4428.8765],\n",
      "         [4426.4004],\n",
      "         [4420.0020],\n",
      "         [4434.9692],\n",
      "         [4419.2349]],\n",
      "\n",
      "        [[4465.8276],\n",
      "         [4463.0024],\n",
      "         [4455.7031],\n",
      "         [4472.7783],\n",
      "         [4454.8276]],\n",
      "\n",
      "        [[4429.9580],\n",
      "         [4421.2617],\n",
      "         [4398.7910],\n",
      "         [4451.3550],\n",
      "         [4396.0957]],\n",
      "\n",
      "        [[4499.0996],\n",
      "         [4493.4106],\n",
      "         [4478.7109],\n",
      "         [4513.0972],\n",
      "         [4476.9478]],\n",
      "\n",
      "        [[4532.9443],\n",
      "         [4531.3652],\n",
      "         [4527.2847],\n",
      "         [4536.8296],\n",
      "         [4526.7954]],\n",
      "\n",
      "        [[4474.1777],\n",
      "         [4468.6899],\n",
      "         [4454.5107],\n",
      "         [4487.6792],\n",
      "         [4452.8101]],\n",
      "\n",
      "        [[4411.3716],\n",
      "         [4399.9121],\n",
      "         [4370.3022],\n",
      "         [4439.5664],\n",
      "         [4366.7510]],\n",
      "\n",
      "        [[4432.8926],\n",
      "         [4423.2349],\n",
      "         [4398.2803],\n",
      "         [4456.6543],\n",
      "         [4395.2876]],\n",
      "\n",
      "        [[4337.6475],\n",
      "         [4332.0952],\n",
      "         [4317.7490],\n",
      "         [4351.3081],\n",
      "         [4316.0288]],\n",
      "\n",
      "        [[4382.6382],\n",
      "         [4377.3657],\n",
      "         [4363.7412],\n",
      "         [4395.6113],\n",
      "         [4362.1074]],\n",
      "\n",
      "        [[4482.1001],\n",
      "         [4475.7856],\n",
      "         [4459.4692],\n",
      "         [4497.6367],\n",
      "         [4457.5127]],\n",
      "\n",
      "        [[4559.2686],\n",
      "         [4556.2432],\n",
      "         [4548.4263],\n",
      "         [4566.7119],\n",
      "         [4547.4888]],\n",
      "\n",
      "        [[4609.9902],\n",
      "         [4605.0977],\n",
      "         [4592.4546],\n",
      "         [4622.0288],\n",
      "         [4590.9385]],\n",
      "\n",
      "        [[4698.1255],\n",
      "         [4696.5469],\n",
      "         [4692.4688],\n",
      "         [4702.0083],\n",
      "         [4691.9795]],\n",
      "\n",
      "        [[4684.8833],\n",
      "         [4680.9927],\n",
      "         [4670.9404],\n",
      "         [4694.4551],\n",
      "         [4669.7349]],\n",
      "\n",
      "        [[4700.3262],\n",
      "         [4697.5259],\n",
      "         [4690.2905],\n",
      "         [4707.2158],\n",
      "         [4689.4224]],\n",
      "\n",
      "        [[4610.3037],\n",
      "         [4596.5229],\n",
      "         [4560.9160],\n",
      "         [4644.2085],\n",
      "         [4556.6460]],\n",
      "\n",
      "        [[4642.1611],\n",
      "         [4627.3213],\n",
      "         [4588.9766],\n",
      "         [4678.6729],\n",
      "         [4584.3779]],\n",
      "\n",
      "        [[4678.9526],\n",
      "         [4670.6147],\n",
      "         [4649.0708],\n",
      "         [4699.4673],\n",
      "         [4646.4868]],\n",
      "\n",
      "        [[4627.6865],\n",
      "         [4615.4956],\n",
      "         [4583.9961],\n",
      "         [4657.6807],\n",
      "         [4580.2183]],\n",
      "\n",
      "        [[4789.4883],\n",
      "         [4787.9790],\n",
      "         [4784.0786],\n",
      "         [4793.2017],\n",
      "         [4783.6108]],\n",
      "\n",
      "        [[4765.0273],\n",
      "         [4752.6309],\n",
      "         [4720.5996],\n",
      "         [4795.5273],\n",
      "         [4716.7578]],\n",
      "\n",
      "        [[4704.4468],\n",
      "         [4696.8408],\n",
      "         [4677.1875],\n",
      "         [4723.1611],\n",
      "         [4674.8301]],\n",
      "\n",
      "        [[4521.3462],\n",
      "         [4504.4375],\n",
      "         [4460.7466],\n",
      "         [4562.9487],\n",
      "         [4455.5068]],\n",
      "\n",
      "        [[4386.2231],\n",
      "         [4376.3516],\n",
      "         [4350.8438],\n",
      "         [4410.5122],\n",
      "         [4347.7847]],\n",
      "\n",
      "        [[4541.1206],\n",
      "         [4530.4795],\n",
      "         [4502.9829],\n",
      "         [4567.3027],\n",
      "         [4499.6855]],\n",
      "\n",
      "        [[4532.3325],\n",
      "         [4517.2925],\n",
      "         [4478.4307],\n",
      "         [4569.3369],\n",
      "         [4473.7700]],\n",
      "\n",
      "        [[4431.9546],\n",
      "         [4419.1626],\n",
      "         [4386.1089],\n",
      "         [4463.4282],\n",
      "         [4382.1445]],\n",
      "\n",
      "        [[4314.8296],\n",
      "         [4293.6050],\n",
      "         [4238.7622],\n",
      "         [4367.0508],\n",
      "         [4232.1851]],\n",
      "\n",
      "        [[4339.3975],\n",
      "         [4321.8516],\n",
      "         [4276.5142],\n",
      "         [4382.5679],\n",
      "         [4271.0767]],\n",
      "\n",
      "        [[4240.7422],\n",
      "         [4230.6064],\n",
      "         [4204.4165],\n",
      "         [4265.6802],\n",
      "         [4201.2754]],\n",
      "\n",
      "        [[4425.3652],\n",
      "         [4414.1528],\n",
      "         [4385.1821],\n",
      "         [4452.9517],\n",
      "         [4381.7075]],\n",
      "\n",
      "        [[4532.4355],\n",
      "         [4523.5181],\n",
      "         [4500.4771],\n",
      "         [4554.3755],\n",
      "         [4497.7139]],\n",
      "\n",
      "        [[4564.3438],\n",
      "         [4557.4927],\n",
      "         [4539.7896],\n",
      "         [4581.2007],\n",
      "         [4537.6665]],\n",
      "\n",
      "        [[4479.6187],\n",
      "         [4471.3647],\n",
      "         [4450.0376],\n",
      "         [4499.9263],\n",
      "         [4447.4800]],\n",
      "\n",
      "        [[4422.0225],\n",
      "         [4413.5933],\n",
      "         [4391.8145],\n",
      "         [4442.7603],\n",
      "         [4389.2021]],\n",
      "\n",
      "        [[4288.9092],\n",
      "         [4271.3135],\n",
      "         [4225.8467],\n",
      "         [4332.2026],\n",
      "         [4220.3940]],\n",
      "\n",
      "        [[4177.4683],\n",
      "         [4165.7354],\n",
      "         [4135.4180],\n",
      "         [4206.3364],\n",
      "         [4131.7822]],\n",
      "\n",
      "        [[4075.4204],\n",
      "         [4060.2314],\n",
      "         [4020.9851],\n",
      "         [4112.7905],\n",
      "         [4016.2783]],\n",
      "\n",
      "        [[4026.6748],\n",
      "         [4016.2520],\n",
      "         [3989.3206],\n",
      "         [4052.3191],\n",
      "         [3986.0906]],\n",
      "\n",
      "        [[3937.0613],\n",
      "         [3930.7742],\n",
      "         [3914.5288],\n",
      "         [3952.5303],\n",
      "         [3912.5806]],\n",
      "\n",
      "        [[4129.4468],\n",
      "         [4121.5381],\n",
      "         [4101.1035],\n",
      "         [4148.9043],\n",
      "         [4098.6528]],\n",
      "\n",
      "        [[4129.6006],\n",
      "         [4124.0737],\n",
      "         [4109.7920],\n",
      "         [4143.1997],\n",
      "         [4108.0791]],\n",
      "\n",
      "        [[3781.7773],\n",
      "         [3772.4019],\n",
      "         [3748.1763],\n",
      "         [3804.8450],\n",
      "         [3745.2710]],\n",
      "\n",
      "        [[3758.8108],\n",
      "         [3751.6750],\n",
      "         [3733.2371],\n",
      "         [3776.3674],\n",
      "         [3731.0256]],\n",
      "\n",
      "        [[3840.3257],\n",
      "         [3829.2974],\n",
      "         [3800.8013],\n",
      "         [3867.4597],\n",
      "         [3797.3838]],\n",
      "\n",
      "        [[3872.6575],\n",
      "         [3865.2493],\n",
      "         [3846.1079],\n",
      "         [3890.8840],\n",
      "         [3843.8123]],\n",
      "\n",
      "        [[3805.8376],\n",
      "         [3797.0188],\n",
      "         [3774.2314],\n",
      "         [3827.5356],\n",
      "         [3771.4985]],\n",
      "\n",
      "        [[3965.9119],\n",
      "         [3960.5728],\n",
      "         [3946.7766],\n",
      "         [3979.0483],\n",
      "         [3945.1223]],\n",
      "\n",
      "        [[4051.2800],\n",
      "         [4035.9514],\n",
      "         [3996.3438],\n",
      "         [4088.9944],\n",
      "         [3991.5938]],\n",
      "\n",
      "        [[4146.1978],\n",
      "         [4141.5625],\n",
      "         [4129.5845],\n",
      "         [4157.6030],\n",
      "         [4128.1479]],\n",
      "\n",
      "        [[4227.0713],\n",
      "         [4218.5249],\n",
      "         [4196.4414],\n",
      "         [4248.0986],\n",
      "         [4193.7930]],\n",
      "\n",
      "        [[4271.5308],\n",
      "         [4266.3159],\n",
      "         [4252.8413],\n",
      "         [4284.3613],\n",
      "         [4251.2256]],\n",
      "\n",
      "        [[4143.6162],\n",
      "         [4131.7285],\n",
      "         [4101.0107],\n",
      "         [4172.8657],\n",
      "         [4097.3267]],\n",
      "\n",
      "        [[3961.3911],\n",
      "         [3954.5466],\n",
      "         [3936.8613],\n",
      "         [3978.2312],\n",
      "         [3934.7402]],\n",
      "\n",
      "        [[4042.5300],\n",
      "         [4029.1541],\n",
      "         [3994.5920],\n",
      "         [4075.4402],\n",
      "         [3990.4470]],\n",
      "\n",
      "        [[3901.2209],\n",
      "         [3895.9153],\n",
      "         [3882.2063],\n",
      "         [3914.2747],\n",
      "         [3880.5623]],\n",
      "\n",
      "        [[3731.1958],\n",
      "         [3719.4556],\n",
      "         [3689.1196],\n",
      "         [3760.0818],\n",
      "         [3685.4814]],\n",
      "\n",
      "        [[3651.4314],\n",
      "         [3642.0469],\n",
      "         [3617.7986],\n",
      "         [3674.5208],\n",
      "         [3614.8906]],\n",
      "\n",
      "        [[3705.8228],\n",
      "         [3690.1074],\n",
      "         [3649.5002],\n",
      "         [3744.4890],\n",
      "         [3644.6304]],\n",
      "\n",
      "        [[3640.0476],\n",
      "         [3622.9624],\n",
      "         [3578.8162],\n",
      "         [3682.0837],\n",
      "         [3573.5220]],\n",
      "\n",
      "        [[3722.0007],\n",
      "         [3707.9929],\n",
      "         [3671.7983],\n",
      "         [3756.4656],\n",
      "         [3667.4575]],\n",
      "\n",
      "        [[3851.1780],\n",
      "         [3841.6616],\n",
      "         [3817.0723],\n",
      "         [3874.5920],\n",
      "         [3814.1233]],\n",
      "\n",
      "        [[3764.9197],\n",
      "         [3756.9998],\n",
      "         [3736.5359],\n",
      "         [3784.4055],\n",
      "         [3734.0815]],\n",
      "\n",
      "        [[3954.0347],\n",
      "         [3942.3540],\n",
      "         [3912.1726],\n",
      "         [3982.7734],\n",
      "         [3908.5530]],\n",
      "\n",
      "        [[3952.5303],\n",
      "         [3948.1045],\n",
      "         [3936.6685],\n",
      "         [3963.4197],\n",
      "         [3935.2969]],\n",
      "\n",
      "        [[4000.4460],\n",
      "         [3992.9026],\n",
      "         [3973.4109],\n",
      "         [4019.0061],\n",
      "         [3971.0732]],\n",
      "\n",
      "        [[4029.0273],\n",
      "         [4017.0159],\n",
      "         [3985.9795],\n",
      "         [4058.5803],\n",
      "         [3982.2573]],\n",
      "\n",
      "        [[3973.4004],\n",
      "         [3964.9490],\n",
      "         [3943.1113],\n",
      "         [3994.1941],\n",
      "         [3940.4924]],\n",
      "\n",
      "        [[3851.9688],\n",
      "         [3845.1077],\n",
      "         [3827.3789],\n",
      "         [3868.8501],\n",
      "         [3825.2527]],\n",
      "\n",
      "        [[3827.1746],\n",
      "         [3821.2974],\n",
      "         [3806.1116],\n",
      "         [3841.6343],\n",
      "         [3804.2903]],\n",
      "\n",
      "        [[3838.8713],\n",
      "         [3834.3474],\n",
      "         [3822.6587],\n",
      "         [3850.0015],\n",
      "         [3821.2568]],\n",
      "\n",
      "        [[3944.6687],\n",
      "         [3935.7966],\n",
      "         [3912.8726],\n",
      "         [3966.4971],\n",
      "         [3910.1233]],\n",
      "\n",
      "        [[3949.7593],\n",
      "         [3939.7212],\n",
      "         [3913.7844],\n",
      "         [3974.4565],\n",
      "         [3910.6738]],\n",
      "\n",
      "        [[4038.8030],\n",
      "         [4030.6248],\n",
      "         [4009.4934],\n",
      "         [4058.9241],\n",
      "         [4006.9592]],\n",
      "\n",
      "        [[4139.4844],\n",
      "         [4129.7861],\n",
      "         [4104.7261],\n",
      "         [4163.3467],\n",
      "         [4101.7207]],\n",
      "\n",
      "        [[4122.5513],\n",
      "         [4115.1904],\n",
      "         [4096.1714],\n",
      "         [4140.6611],\n",
      "         [4093.8906]],\n",
      "\n",
      "        [[4114.5186],\n",
      "         [4108.3174],\n",
      "         [4092.2935],\n",
      "         [4129.7769],\n",
      "         [4090.3716]],\n",
      "\n",
      "        [[3994.8792],\n",
      "         [3989.6372],\n",
      "         [3976.0923],\n",
      "         [4007.7766],\n",
      "         [3974.4680]],\n",
      "\n",
      "        [[4009.7439],\n",
      "         [3999.0566],\n",
      "         [3971.4419],\n",
      "         [4036.0388],\n",
      "         [3968.1301]],\n",
      "\n",
      "        [[3918.5464],\n",
      "         [3905.2253],\n",
      "         [3870.8052],\n",
      "         [3951.3213],\n",
      "         [3866.6772]],\n",
      "\n",
      "        [[3938.8005],\n",
      "         [3930.6580],\n",
      "         [3909.6182],\n",
      "         [3958.8347],\n",
      "         [3907.0950]],\n",
      "\n",
      "        [[3961.6223],\n",
      "         [3957.9875],\n",
      "         [3948.5955],\n",
      "         [3970.5657],\n",
      "         [3947.4690]],\n",
      "\n",
      "        [[4083.3110],\n",
      "         [4074.8499],\n",
      "         [4052.9878],\n",
      "         [4104.1284],\n",
      "         [4050.3657]],\n",
      "\n",
      "        [[4100.0430],\n",
      "         [4096.8916],\n",
      "         [4088.7478],\n",
      "         [4107.7974],\n",
      "         [4087.7710]],\n",
      "\n",
      "        [[4145.5347],\n",
      "         [4143.6182],\n",
      "         [4138.6655],\n",
      "         [4150.2505],\n",
      "         [4138.0718]],\n",
      "\n",
      "        [[4125.6978],\n",
      "         [4119.2500],\n",
      "         [4102.5894],\n",
      "         [4141.5625],\n",
      "         [4100.5908]],\n",
      "\n",
      "        [[4154.4927],\n",
      "         [4148.9136],\n",
      "         [4134.4990],\n",
      "         [4168.2183],\n",
      "         [4132.7705]],\n",
      "\n",
      "        [[4126.6689],\n",
      "         [4121.3867],\n",
      "         [4107.7378],\n",
      "         [4139.6650],\n",
      "         [4106.1011]],\n",
      "\n",
      "        [[4128.9009],\n",
      "         [4126.2583],\n",
      "         [4119.4302],\n",
      "         [4135.4028],\n",
      "         [4118.6113]],\n",
      "\n",
      "        [[4188.6274],\n",
      "         [4183.3677],\n",
      "         [4169.7778],\n",
      "         [4201.5674],\n",
      "         [4168.1484]],\n",
      "\n",
      "        [[4199.0552],\n",
      "         [4192.7485],\n",
      "         [4176.4521],\n",
      "         [4214.5728],\n",
      "         [4174.4976]],\n",
      "\n",
      "        [[4277.0454],\n",
      "         [4275.3706],\n",
      "         [4271.0435],\n",
      "         [4281.1655],\n",
      "         [4270.5244]],\n",
      "\n",
      "        [[4352.4341],\n",
      "         [4346.3882],\n",
      "         [4330.7656],\n",
      "         [4367.3101],\n",
      "         [4328.8921]],\n",
      "\n",
      "        [[4384.2793],\n",
      "         [4381.6553],\n",
      "         [4374.8755],\n",
      "         [4390.7349],\n",
      "         [4374.0625]],\n",
      "\n",
      "        [[4374.7510],\n",
      "         [4369.7280],\n",
      "         [4356.7485],\n",
      "         [4387.1104],\n",
      "         [4355.1919]],\n",
      "\n",
      "        [[4427.6069],\n",
      "         [4422.9316],\n",
      "         [4410.8506],\n",
      "         [4439.1108],\n",
      "         [4409.4014]],\n",
      "\n",
      "        [[4492.3901],\n",
      "         [4487.9702],\n",
      "         [4476.5493],\n",
      "         [4503.2651],\n",
      "         [4475.1797]],\n",
      "\n",
      "        [[4553.3755],\n",
      "         [4549.9609],\n",
      "         [4541.1372],\n",
      "         [4561.7773],\n",
      "         [4540.0791]],\n",
      "\n",
      "        [[4572.3892],\n",
      "         [4567.0366],\n",
      "         [4553.2065],\n",
      "         [4585.5586],\n",
      "         [4551.5479]],\n",
      "\n",
      "        [[4512.0464],\n",
      "         [4505.7056],\n",
      "         [4489.3213],\n",
      "         [4527.6475],\n",
      "         [4487.3564]],\n",
      "\n",
      "        [[4480.4043],\n",
      "         [4476.6968],\n",
      "         [4467.1182],\n",
      "         [4489.5249],\n",
      "         [4465.9692]],\n",
      "\n",
      "        [[4403.4038],\n",
      "         [4396.8330],\n",
      "         [4379.8545],\n",
      "         [4419.5703],\n",
      "         [4377.8184]],\n",
      "\n",
      "        [[4418.9312],\n",
      "         [4411.6260],\n",
      "         [4392.7500],\n",
      "         [4436.9048],\n",
      "         [4390.4863]],\n",
      "\n",
      "        [[4512.2485],\n",
      "         [4510.6157],\n",
      "         [4506.3979],\n",
      "         [4516.2646],\n",
      "         [4505.8921]],\n",
      "\n",
      "        [[4459.4590],\n",
      "         [4454.9766],\n",
      "         [4443.3945],\n",
      "         [4470.4878],\n",
      "         [4442.0054]],\n",
      "\n",
      "        [[4482.9814],\n",
      "         [4477.0859],\n",
      "         [4461.8521],\n",
      "         [4497.4873],\n",
      "         [4460.0249]],\n",
      "\n",
      "        [[4343.9780],\n",
      "         [4339.2222],\n",
      "         [4326.9336],\n",
      "         [4355.6792],\n",
      "         [4325.4600]],\n",
      "\n",
      "        [[4298.2148],\n",
      "         [4293.2217],\n",
      "         [4280.3203],\n",
      "         [4310.4995],\n",
      "         [4278.7734]],\n",
      "\n",
      "        [[4285.8618],\n",
      "         [4276.2695],\n",
      "         [4251.4844],\n",
      "         [4309.4624],\n",
      "         [4248.5117]],\n",
      "\n",
      "        [[4361.8188],\n",
      "         [4356.9595],\n",
      "         [4344.4043],\n",
      "         [4373.7739],\n",
      "         [4342.8984]],\n",
      "\n",
      "        [[4269.6953],\n",
      "         [4259.7500],\n",
      "         [4234.0527],\n",
      "         [4294.1646],\n",
      "         [4230.9707]],\n",
      "\n",
      "        [[4153.7861],\n",
      "         [4148.3589],\n",
      "         [4134.3350],\n",
      "         [4167.1396],\n",
      "         [4132.6533]],\n",
      "\n",
      "        [[4335.1025],\n",
      "         [4326.0757],\n",
      "         [4302.7515],\n",
      "         [4357.3115],\n",
      "         [4299.9546]],\n",
      "\n",
      "        [[4390.6416],\n",
      "         [4383.7798],\n",
      "         [4366.0493],\n",
      "         [4407.5249],\n",
      "         [4363.9229]],\n",
      "\n",
      "        [[4518.2720],\n",
      "         [4513.8667],\n",
      "         [4502.4854],\n",
      "         [4529.1094],\n",
      "         [4501.1201]],\n",
      "\n",
      "        [[4555.5767],\n",
      "         [4554.8398],\n",
      "         [4552.9365],\n",
      "         [4557.3887],\n",
      "         [4552.7080]],\n",
      "\n",
      "        [[4573.2549],\n",
      "         [4570.0776],\n",
      "         [4561.8672],\n",
      "         [4581.0728],\n",
      "         [4560.8828]],\n",
      "\n",
      "        [[4612.1606],\n",
      "         [4606.1177],\n",
      "         [4590.5029],\n",
      "         [4627.0288],\n",
      "         [4588.6304]],\n",
      "\n",
      "        [[4737.0503],\n",
      "         [4731.9946],\n",
      "         [4718.9307],\n",
      "         [4749.4897],\n",
      "         [4717.3638]],\n",
      "\n",
      "        [[4766.7520],\n",
      "         [4763.8262],\n",
      "         [4756.2671],\n",
      "         [4773.9497],\n",
      "         [4755.3608]],\n",
      "\n",
      "        [[4725.1938],\n",
      "         [4719.5361],\n",
      "         [4704.9175],\n",
      "         [4739.1143],\n",
      "         [4703.1641]],\n",
      "\n",
      "        [[4767.1626],\n",
      "         [4763.1479],\n",
      "         [4752.7739],\n",
      "         [4777.0410],\n",
      "         [4751.5298]],\n",
      "\n",
      "        [[4778.4668],\n",
      "         [4768.7910],\n",
      "         [4743.7905],\n",
      "         [4802.2729],\n",
      "         [4740.7920]],\n",
      "\n",
      "        [[4887.3726],\n",
      "         [4885.0483],\n",
      "         [4879.0425],\n",
      "         [4893.0918],\n",
      "         [4878.3223]],\n",
      "\n",
      "        [[4901.1455],\n",
      "         [4890.9341],\n",
      "         [4864.5483],\n",
      "         [4926.2700],\n",
      "         [4861.3838]],\n",
      "\n",
      "        [[5000.5869],\n",
      "         [4996.1650],\n",
      "         [4984.7397],\n",
      "         [5011.4663],\n",
      "         [4983.3696]],\n",
      "\n",
      "        [[5006.1040],\n",
      "         [5001.7197],\n",
      "         [4990.3911],\n",
      "         [5016.8911],\n",
      "         [4989.0322]],\n",
      "\n",
      "        [[5080.8491],\n",
      "         [5075.2632],\n",
      "         [5060.8301],\n",
      "         [5094.5923],\n",
      "         [5059.0991]],\n",
      "\n",
      "        [[5113.2705],\n",
      "         [5107.9624],\n",
      "         [5094.2471],\n",
      "         [5126.3301],\n",
      "         [5092.6021]],\n",
      "\n",
      "        [[5142.4448],\n",
      "         [5137.6582],\n",
      "         [5125.2910],\n",
      "         [5154.2212],\n",
      "         [5123.8076]],\n",
      "\n",
      "        [[5146.8022],\n",
      "         [5141.3813],\n",
      "         [5127.3755],\n",
      "         [5160.1387],\n",
      "         [5125.6958]],\n",
      "\n",
      "        [[5240.0283],\n",
      "         [5237.0122],\n",
      "         [5229.2197],\n",
      "         [5247.4482],\n",
      "         [5228.2852]],\n",
      "\n",
      "        [[5245.3125],\n",
      "         [5240.4570],\n",
      "         [5227.9102],\n",
      "         [5257.2598],\n",
      "         [5226.4053]],\n",
      "\n",
      "        [[5200.8545],\n",
      "         [5195.8008],\n",
      "         [5182.7417],\n",
      "         [5213.2896],\n",
      "         [5181.1758]],\n",
      "\n",
      "        [[5119.9937],\n",
      "         [5107.6899],\n",
      "         [5075.8984],\n",
      "         [5150.2651],\n",
      "         [5072.0859]],\n",
      "\n",
      "        [[5014.3853],\n",
      "         [5005.4004],\n",
      "         [4982.1841],\n",
      "         [5036.4917],\n",
      "         [4979.3999]],\n",
      "\n",
      "        [[5095.3516],\n",
      "         [5087.7158],\n",
      "         [5067.9849],\n",
      "         [5114.1392],\n",
      "         [5065.6187]],\n",
      "\n",
      "        [[5157.0693],\n",
      "         [5150.0879],\n",
      "         [5132.0479],\n",
      "         [5174.2471],\n",
      "         [5129.8843]],\n",
      "\n",
      "        [[5231.5259],\n",
      "         [5229.1089],\n",
      "         [5222.8647],\n",
      "         [5237.4722],\n",
      "         [5222.1157]],\n",
      "\n",
      "        [[5309.4634],\n",
      "         [5307.6953],\n",
      "         [5303.1265],\n",
      "         [5313.8135],\n",
      "         [5302.5786]],\n",
      "\n",
      "        [[5298.2129],\n",
      "         [5293.5439],\n",
      "         [5281.4810],\n",
      "         [5309.6997],\n",
      "         [5280.0342]],\n",
      "\n",
      "        [[5305.6914],\n",
      "         [5298.5986],\n",
      "         [5280.2725],\n",
      "         [5323.1416],\n",
      "         [5278.0747]],\n",
      "\n",
      "        [[5375.1870],\n",
      "         [5368.0137],\n",
      "         [5349.4780],\n",
      "         [5392.8369],\n",
      "         [5347.2554]],\n",
      "\n",
      "        [[5471.5454],\n",
      "         [5466.5713],\n",
      "         [5453.7188],\n",
      "         [5483.7837],\n",
      "         [5452.1777]],\n",
      "\n",
      "        [[5471.8901],\n",
      "         [5469.5723],\n",
      "         [5463.5830],\n",
      "         [5477.5933],\n",
      "         [5462.8647]],\n",
      "\n",
      "        [[5522.7070],\n",
      "         [5513.6465],\n",
      "         [5490.2354],\n",
      "         [5544.9995],\n",
      "         [5487.4277]],\n",
      "\n",
      "        [[5615.7886],\n",
      "         [5610.3374],\n",
      "         [5596.2515],\n",
      "         [5629.2012],\n",
      "         [5594.5620]],\n",
      "\n",
      "        [[5578.5239],\n",
      "         [5567.9766],\n",
      "         [5540.7236],\n",
      "         [5604.4741],\n",
      "         [5537.4551]],\n",
      "\n",
      "        [[5450.4351],\n",
      "         [5441.0405],\n",
      "         [5416.7651],\n",
      "         [5473.5498],\n",
      "         [5413.8540]],\n",
      "\n",
      "        [[5484.1846],\n",
      "         [5466.0991],\n",
      "         [5419.3691],\n",
      "         [5528.6812],\n",
      "         [5413.7646]],\n",
      "\n",
      "        [[5290.8018],\n",
      "         [5277.5664],\n",
      "         [5243.3672],\n",
      "         [5323.3657],\n",
      "         [5239.2661]],\n",
      "\n",
      "        [[5507.2261],\n",
      "         [5495.5615],\n",
      "         [5465.4209],\n",
      "         [5535.9258],\n",
      "         [5461.8062]],\n",
      "\n",
      "        [[5617.7642],\n",
      "         [5611.3828],\n",
      "         [5594.8940],\n",
      "         [5633.4644],\n",
      "         [5592.9170]],\n",
      "\n",
      "        [[5616.6719],\n",
      "         [5611.1230],\n",
      "         [5596.7847],\n",
      "         [5630.3247],\n",
      "         [5595.0654]]])\n",
      "Training losses: <class 'list'>\n",
      "Validation losses: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self):\n",
    "        self.seq_len = 5  # Input sequence length (number of time steps)\n",
    "        # Output prediction length (number of future time steps)\n",
    "        self.pred_len = 5\n",
    "        self.d_model = 1  # Number of features per input (matches input data)\n",
    "        # Number of attention heads (since d_model is 1, set n_heads to 1)\n",
    "        self.n_heads = 1\n",
    "        self.d_ff = 4  # Dimension of feed-forward network (can be adjusted)\n",
    "        self.dropout = 0.1  # Dropout rate\n",
    "        self.activation = 'relu'  # Activation function\n",
    "        self.e_layers = 2  # Number of encoder layers\n",
    "        self.factor = 5  # Factor for the FullAttention layer\n",
    "        self.output_attention = False  # Whether to output attention weights\n",
    "        self.embed = 'fixed'  # Embedding type\n",
    "        self.freq = 'h'  # Frequency of the time series data\n",
    "        self.use_norm = True  # Whether to use normalization\n",
    "        self.class_strategy = 'forecast'  # Strategy for classification\n",
    "\n",
    "\n",
    "# Convert the processed data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Initialize configurations and model\n",
    "configs = Configs()\n",
    "model = Model(configs)\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor, X_train_tensor,\n",
    "                    X_test_tensor, X_test_tensor)\n",
    "    train_losses.append(loss.item())\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Evaluate the model (this is a simple example, adjust as needed)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor, X_test_tensor,\n",
    "                            X_test_tensor, X_test_tensor)\n",
    "        val_loss = criterion(predictions, y_test_tensor)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    # Print loss\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(f'Predictions: {predictions}')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
